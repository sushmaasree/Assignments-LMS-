{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOa15zIzWMXoHPrPNCB699M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushmaasree/Assignments-LMS-/blob/main/Day7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn3xpd9Nxz6E",
        "outputId": "35dbc3bf-2b6d-44bd-e97f-1b4fcff2a4bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "\n",
            "Natural Language Processing (NLP) is an exciting and rapidly evolving field in the world of Artificial Intelligence (AI). \n",
            "It deals with the interaction between computers and human language, enabling machines to understand, interpret, and respond to human language in a meaningful way.\n",
            "\n",
            "\n",
            "Processed Text:\n",
            "['natur', 'languag', 'process', 'nlp', 'excit', 'rapidli', 'evolv', 'field', 'world', 'artifici', 'intellig', 'ai', 'deal', 'interact', 'comput', 'human', 'languag', 'enabl', 'machin', 'understand', 'interpret', 'respond', 'human', 'languag', 'meaning', 'way']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import spacy\n",
        "\n",
        "# Load spaCy model for lemmatization\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample text (substitute for reading from a file)\n",
        "text = \"\"\"\n",
        "Natural Language Processing (NLP) is an exciting and rapidly evolving field in the world of Artificial Intelligence (AI).\n",
        "It deals with the interaction between computers and human language, enabling machines to understand, interpret, and respond to human language in a meaningful way.\n",
        "\"\"\"\n",
        "\n",
        "# Preprocessing steps: Tokenization, Stemming, Lemmatization\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text using Gensim's simple_preprocess\n",
        "    tokens = simple_preprocess(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Initialize the Porter Stemmer\n",
        "    porter_stemmer = PorterStemmer()\n",
        "    tokens_stemmed = [porter_stemmer.stem(token) for token in tokens]\n",
        "\n",
        "    # Lemmatization using spaCy\n",
        "    doc = nlp(\" \".join(tokens_stemmed))\n",
        "    lemmatized_tokens = [token.lemma_ for token in doc]\n",
        "\n",
        "    return lemmatized_tokens\n",
        "\n",
        "# Preprocess the sample text\n",
        "processed_text = preprocess_text(text)\n",
        "\n",
        "# Print the results\n",
        "print(\"Original Text:\")\n",
        "print(text[:500])  # Print first 500 characters of the original text\n",
        "print(\"\\nProcessed Text:\")\n",
        "print(processed_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rJHhIPNLyFYY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}